{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from pprint import pprint\n",
    "import time\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopword():\n",
    "    #stopword_path = 'F:\\\\编程练习\\\\Jupyter notebook\\\\文本文件夹\\\\博客爬虫分析文章\\\\停用词表.txt'\n",
    "    #stopword_path = 'F:\\\\学习用夹\\\\大三下学期\\\\综合课程设计\\\\实验数据\\\\停用词库.txt'\n",
    "    stopword_path = 'F:\\\\学习用夹\\\\大三下学期\\\\综合课程设计\\\\实验数据\\\\scu_stopwords.txt'\n",
    "    f_stop = open(stopword_path,'r',encoding='UTF-8')\n",
    "    sw = [line.strip() for line in f_stop]\n",
    "    f_stop.close()\n",
    "    stopword_extend = ['\\n','湖北','武汉','病毒','中国',\n",
    "                       '兰州','甘肃','我国','北京','微博','正文',\n",
    "                       '收起','肖战','消费','复工','复产','全文','消费者','疫情','网页','链接','美国','浙江','杭州','新冠','市场']\n",
    "    sw.extend(stopword_extend)\n",
    "    return sw\n",
    "\n",
    "\n",
    "def jieba_text(data_path):\n",
    "    stopwords = load_stopword()\n",
    "    df = pd.read_excel(data_path)\n",
    "    #df = pd.read_csv(data_path)\n",
    "    text_seg_list = []\n",
    "    text_id_list = []\n",
    "    for index,row in df.iterrows():\n",
    "        fileId = row['id']\n",
    "        fileContent = row['内容']\n",
    "        segs = jieba.analyse.textrank(fileContent,topK=20,withWeight=False,allowPOS=('ns','n','nr','nt','vn')) \n",
    "        segments_list = []\n",
    "        for seg in segs:\n",
    "            if seg not in stopwords and len(seg) > 1:\n",
    "                segments_list.append(seg)\n",
    "        text_seg_list.append(segments_list)\n",
    "        text_id_list.append(fileId)\n",
    "        text_seg_list_dic = {'id':text_id_list, 'text':text_seg_list}\n",
    "    return text_seg_list_dic\n",
    "\n",
    "    \n",
    "#导出csv文件\n",
    "def dataToCsv(file,df):\n",
    "    file_data = df\n",
    "    file_data.to_csv(file,index=False)\n",
    "    print('csv文件已生成在：{}'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(text_seg_list_dic,topic_num):\n",
    "    text_seg_list = text_seg_list_dic['text']\n",
    "    # 建立字典\n",
    "    dictionary = corpora.Dictionary(text_seg_list)\n",
    "    V = len(dictionary)\n",
    "\n",
    "    # 转换文本数据为索引，并计数\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_seg_list]\n",
    "\n",
    "    # 计算tf-idf值\n",
    "    corpus_tfidf = models.TfidfModel(corpus)[corpus]\n",
    "\n",
    "    # 训练模型\n",
    "    lda = models.LdaModel(corpus_tfidf, num_topics=topic_num, id2word=dictionary)\n",
    "    #alpha=0.01, eta=0.01, minimum_probability=0.001,update_every=1, chunksize=100, passes=1\n",
    "    Perplexity = lda.log_perplexity(corpus_tfidf)\n",
    "\n",
    "    num_show_term = 10  # 每个主题显示几个词\n",
    "    #print('结果：每个主题的词分布：')\n",
    "    lda_topic = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[]}\n",
    "    lda_topic_prob = []\n",
    "    for topic_id in range(topic_num):\n",
    "        #print('主题#%d：\\t' % topic_id)\n",
    "        term_distribute_all = lda.get_topic_terms(topicid=topic_id)\n",
    "        term_distribute = term_distribute_all[:num_show_term]\n",
    "        term_distribute = np.array(term_distribute)\n",
    "        term_id = term_distribute[:, 0].astype(np.int)\n",
    "        #print('词：\\t', )\n",
    "        i = 0\n",
    "        for t in term_id:\n",
    "            i += 1\n",
    "            #print(dictionary.id2token[t], )\n",
    "            lda_topic[str(i)].append(dictionary.id2token[t])\n",
    "        #print('\\n概率：\\t', term_distribute[:, 1])\n",
    "        lda_topic_prob.append(term_distribute[:, 1])\n",
    "    #print(lda.print_topics(5))\n",
    "    \n",
    "    #lda可视化\n",
    "    vis_data = pyLDAvis.gensim.prepare(lda,corpus_tfidf,dictionary)\n",
    "    #pyLDAvis.show(vis_data,open_browser = False)\n",
    "    \n",
    "    #输出每个list所属的类别\n",
    "    topic_list=[]\n",
    "    for topics in lda.get_document_topics(corpus)[:]:\n",
    "        #print(topics)\n",
    "        listj=[]\n",
    "        for j in topics:\n",
    "            listj.append(j[1])\n",
    "        bz=listj.index(max(listj))\n",
    "        topic_list.append(topics[bz][0])\n",
    "    corpus_topic_df = pd.DataFrame({'id':text_seg_list_dic['id'], 'topic':topic_list, 'content':text_seg_list})\n",
    "    dataToCsv('F:\\\\学习用夹\\\\大三下学期\\\\综合课程设计\\\\实验数据\\\\LDA结果\\\\LDA文本分类.csv',corpus_topic_df)\n",
    "    \n",
    "    return lda_topic,lda_topic_prob,Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'F:\\\\学习用夹\\\\大三下学期\\\\综合课程设计\\\\实验数据\\\\微博消费内容数据01-01_06-20.xlsx'\n",
    "data_path_1 = 'F:\\\\学习用夹\\\\大三下学期\\\\综合课程设计\\\\实验数据\\\\消费_实验集.xlsx'\n",
    "\n",
    "text_dic = jieba_text(data_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mu_Xiaobai\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv文件已生成在：F:\\学习用夹\\大三下学期\\综合课程设计\\实验数据\\LDA结果\\LDA文本分类.csv\n"
     ]
    }
   ],
   "source": [
    "lda_topic,lda_topic_prob,Perplexity = LDA(text_dic,10)    #第二个系数为lda主题个数\n",
    "df_topic = pd.DataFrame(lda_topic)\n",
    "df_topic_prob = pd.DataFrame(lda_topic_prob,columns=['1','2','3','4','5','6','7','8','9','10'])\n",
    "#print(df_topic)\n",
    "#print(df_topic_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:statistic]",
   "language": "python",
   "name": "conda-env-statistic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
